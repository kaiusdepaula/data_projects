{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What are Shapley Values?\n",
    "\n",
    "Commonly reffered to as SHAP (SHapley Additive exPlanations) values, they provide a way of understanding the true \"impact\" of a variable/feature in a specific task and how it may impact the outcome of said task.\n",
    "\n",
    "It's as if we try to measure the degree of *\"importance\"* a single contribution to a specific task has.\n",
    "\n",
    "They are based on **Game Theory**, and assign a number to each feature in a model. Features with positive SHAP values positively impact the prediction, while those with negative values have a negative impact."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why am I writing about them? \n",
    "\n",
    "Here is the **importance** ü•Å and usefulness of Shapley Values:\n",
    "\n",
    "* Shapley values provide a robust and mathematically sound method to explain individual predictions of complex models, such as ensemble methods (XGBoost, Random Forest) or neural networks. They help break down the contribution of each feature to a specific prediction, making black-box models more transparent.\n",
    "\n",
    "* Understanding why a model made a certain decision allows you to explain predictions in a way that is consistent and fair, helping users understand and trust the model‚Äôs output.\n",
    "\n",
    "* Shapley values can highlight if certain features are disproportionately influencing decisions, which helps identify and mitigate biases in the model.\n",
    "\n",
    "* They give insight into feature importance on a granular level by considering all possible combinations of features. \n",
    "\n",
    "* In industries like finance or healthcare, regulatory requirements demand model transparency. Shapley values can help meet these requirements by providing explanations for predictions that are mathematically sound and easy to interpret.\n",
    "\n",
    "* By understanding how features contribute to predictions, you can diagnose and fine-tune models more effectively. Shapley values provide insight into potential areas for improvement, such as feature selection, handling outliers, or addressing multicollinearity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SHAP values: definition and properties\n",
    "\n",
    "Shapley Values are computed using the following expression:\n",
    "\n",
    "$$\n",
    "\\phi_j(\\text{val}) = \\sum_{S \\subseteq \\{1,\\dots,p\\} \\setminus \\{j\\}} \\frac{|S|! (p - |S| - 1)!}{p!} \\left( \\text{val}(S \\cup \\{j\\}) - \\text{val}(S) \\right)\n",
    "$$\n",
    "\n",
    "Good lord!\n",
    "\n",
    "Let's break down this expression:\n",
    "\n",
    "1.$\\phi_j(\\text{val})$: This is the **Shapley value** for feature $j$ in the function or model $\\text{val}$. It represents the **contribution** of feature $j$ to the final output of the model. \n",
    "\n",
    "   - **val**: The value function (or payoff function in game theory), which measures the output or gain from a set of features (or players).\n",
    "   - **j**: The index of the feature (or player) for which we are computing the Shapley value.\n",
    "\n",
    "2. **$S \\subseteq \\{1, \\dots, p\\} \\setminus \\{j\\}$**: \n",
    "   - This is a **subset** $S$ of all possible features (or players), except the feature $j$ whose contribution we're trying to calculate.\n",
    "   - It represents all the possible coalitions of features (or players) without including feature $j$.\n",
    "   - Essentially, we look at all subsets $S$ of features that do not contain $j$, and evaluate the effect of adding $j$ to each subset.\n",
    "\n",
    "3. **$\\frac{|S|! (p - |S| - 1)!}{p!}$**: \n",
    "   - This is a **weight** based on the size of the subset $S$. It ensures that each subset is considered in a balanced and fair way.\n",
    "   - Here's a breakdown of this term:\n",
    "     - $|S|!$: The factorial of the size of $S$, which accounts for the number of ways the features in $S$ could be arranged.\n",
    "     - $(p - |S| - 1)!$: The factorial of the remaining features that are not in $S$ or $j$, which accounts for the number of ways the remaining features can be arranged.\n",
    "     - $p!$: The factorial of the total number of features, ensuring the whole expression is normalized (so the contributions from all possible subsets sum up to the full model value).\n",
    "\n",
    "4. **$\\text{val}(S \\cup \\{j\\}) - \\text{val}(S)$**: \n",
    "   - This term represents the **marginal contribution** of feature $j$ to the subset $S$. \n",
    "   - $\\text{val}(S \\cup \\{j\\})$: The output of the value function when feature $j$ is included in the subset $S$.\n",
    "   - $\\text{val}(S)$: The output of the value function when feature $j$ is not included.\n",
    "   - The difference $\\text{val}(S \\cup \\{j\\}) - \\text{val}(S)$ shows how much the prediction (or game value) changes when feature $j$ is added to the subset $S$.\n",
    "\n",
    "\n",
    "A good **example** that can increase the comprehention of the concept may be read below:\n",
    "\n",
    "Imagine a room where guests decide on a matter, and the goal is to decide on the answer to a certain question. In the beginning, before anyone enters the room, there's just a default answer. Let's say it's something vague or neutral, like \"We don't know yet.\"\n",
    "\n",
    "Now, one by one, different people enter the room, each bringing their unique knowledge or perspective. These people are like the features in a machine learning model. Each time someone enters the room, they add value to the decision-making process. The final decision, when everyone is inside the room, is the cumulative result of all the contributions.\n",
    "\n",
    "However, the order in which people enter the room matters for evaluating their contributions, as it may change the way their input is perceived or combined with others'. This is where the Shapley value idea comes in.\n",
    "\n",
    "## Properties\n",
    "\n",
    "SHAP values have several useful properties that make them effective for interpreting models:\n",
    "\n",
    "1. Efficiency (Pareto Optimality): This property ensures that the total value (or payoff) of the game (or model prediction) is completely distributed among all players (or features). The sum of all individual Shapley values is equal to the total value generated by the coalition of all players.\n",
    "\n",
    "$$\n",
    "\\sum_{j=1}^{p} \\phi_j(\\text{val}) = \\text{val}(\\{1, \\dots, p\\})\n",
    "$$\n",
    "\n",
    "2. Symmetry: If two players (or features) contribute the same value to every possible coalition, then their Shapley values should be equal. This ensures that no two features that are equally important (in every context) are treated differently.\n",
    "\n",
    "$$\n",
    "\\text{If for all } S \\subseteq \\{1, \\dots, p\\} \\setminus \\{i, j\\}: \\quad \\text{val}(S \\cup \\{i\\}) = \\text{val}(S \\cup \\{j\\}) \\\\\n",
    "\\text{Then:} \\quad \\phi_i(\\text{val}) = \\phi_j(\\text{val})\n",
    "$$\n",
    "\n",
    "3. Linearity (Additivity): The Shapley value is linear in the value function. If two games (or models) are combined, the Shapley value for each player (or feature) in the combined game is the sum of their Shapley values in each individual game.\n",
    "$$\n",
    "\\phi_j(\\text{val}_1 + \\text{val}_2) = \\phi_j(\\text{val}_1) + \\phi_j(\\text{val}_2)\n",
    "$$\n",
    "\n",
    "\n",
    "4. Null Player (Dummy Player): If a player (or feature) does not contribute anything to any coalition, its Shapley value should be zero. This property ensures that features that add no value are not assigned any contribution.\n",
    "$$\n",
    "\\text{If for all } S \\subseteq \\{1, \\dots, p\\}: \\quad \\text{val}(S \\cup \\{j\\}) = \\text{val}(S) \\\\\n",
    "\\text{Then:} \\quad \\phi_j(\\text{val}) = 0\n",
    "$$\n",
    "\n",
    "5. Marginality: The Shapley value reflects the marginal contribution of each feature. The marginal contribution is how much the inclusion of a feature improves the prediction or value, averaged over all possible subsets of features.\n",
    "\n",
    "$$\n",
    "\\text{Marginal contribution of } j \\text{ to } S = \\text{val}(S \\cup \\{j\\}) - \\text{val}(S)\n",
    "$$\n",
    "\n",
    "In summary:\n",
    "\n",
    "1. Efficiency guarantees that the total output is fully distributed among the features.\n",
    "2. Symmetry ensures that equally contributing features receive equal credit.\n",
    "3. Linearity and Additivity allow for the Shapley value to work with combined or separated models.\n",
    "4. Null Player ensures that uninformative features are assigned zero contribution.\n",
    "5. Marginality highlights that each feature's contribution is measured fairly across all possible subsets.\n",
    "\n",
    "These properties are what make the Shapley value a robust and mathematically sound method for explaining feature importance in machine learning models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manually calculating SHAP values for a linear regression\n",
    "\n",
    "What I've done up there is basically a lot of math to **represent** the **idea** behind the estimation of a shapley value. But the **real** math may vary depending on the situation. I'll provide a simple solution that is computationally expensive.\n",
    "\n",
    "The idea here is quite simple: for every possible coalition generated on a model with 3 features (Intercept, B1 and B2), generate mean predicted values so that we can fill them inside the shap formula. (I'll implement a function to do this automatic later.)\n",
    "\n",
    "A important note is that every contribution is computed in a instance level, which is the same as computing FOR EVERY \"ROW\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is my mock up dataset:\n",
      "    Feature_1  Feature_2  Feature_3      Target\n",
      "0  -0.792521   0.504987  -0.114736   13.510026\n",
      "1   0.280992  -0.208122  -0.622700  -18.777475\n",
      "2   0.791032   1.402794  -0.909387  111.265809\n",
      "3   0.625667  -1.070892  -0.857158  -77.989347\n",
      "4  -0.342715  -0.161286  -0.802277  -35.951738\n",
      "5   2.122156  -1.519370   1.032465  -35.839901\n",
      "6  -1.401851   2.190456   0.586857  135.451953\n",
      "7  -0.908024   1.465649  -1.412304   59.303696\n",
      "8   0.259883  -1.236951   0.781823  -71.595854\n",
      "9  -0.815810   0.341152  -0.077102    1.236046\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from itertools import chain, combinations \n",
    "\n",
    "X, y = make_regression(n_samples=100, n_features=3, noise=0.1, random_state=42)\n",
    "df_X = pd.DataFrame(X, columns=['Feature_1', 'Feature_2', 'Feature_3'])\n",
    "df_y = pd.DataFrame(y, columns=['Target'])\n",
    "df = pd.concat([df_X, df_y], axis=1)\n",
    "\n",
    "print(f\"This is my mock up dataset:\\n {df.head(10)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[28.2045949 , 75.05077568, 17.75449804]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Just messing up here, how are the coefficients for this linear model using OLS\n",
    "model = LinearRegression()\n",
    "model.fit(df_X, df_y)\n",
    "model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The superset defined by 3 features is: [(), ('Feature_1',), ('Feature_2',), ('Feature_3',), ('Feature_1', 'Feature_2'), ('Feature_1', 'Feature_3'), ('Feature_2', 'Feature_3'), ('Feature_1', 'Feature_2', 'Feature_3')]\n"
     ]
    }
   ],
   "source": [
    "features = [\"Feature_1\", \"Feature_2\", \"Feature_3\"]\n",
    "\n",
    "superset = [i for i in chain.from_iterable(combinations(features, r) for r in range(len(features)+1))]\n",
    "print(f\"The superset defined by 3 features is: {superset}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "() 4.962922789987591\n",
      "('Feature_1',) [-8.26237738]\n",
      "('Feature_2',) [35.33023419]\n",
      "('Feature_3',) [5.37670622]\n",
      "('Feature_1', 'Feature_2') [12.6247103]\n",
      "('Feature_1', 'Feature_3') [-8.14604212]\n",
      "('Feature_2', 'Feature_3') [37.20101816]\n",
      "('Feature_1', 'Feature_2', 'Feature_3') [13.52236521]\n"
     ]
    }
   ],
   "source": [
    "instance = df.loc[0, :]\n",
    "for game in superset:\n",
    "    assert len(instance.shape) == 1, 'Instance must be a 1D array'\n",
    "    prediction = 0\n",
    "    if len(game) == 0:\n",
    "        prediction = y.mean()\n",
    "    else:\n",
    "        model = LinearRegression()\n",
    "        model.fit(df[[feature for feature in game]].values, df[\"Target\"])\n",
    "        prediction = model.predict(instance.loc[[feature for feature in game]].values.reshape(1, -1))\n",
    "\n",
    "    print(game, prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a single instance, we shall have the following coalisions:\n",
    "$$\n",
    "() = 4.96 \\newline\n",
    "(Feature_1) = -8.26 \\newline\n",
    "(Feature_2) = 35.33 \\newline\n",
    "(Feature_3) = 5.37 \\newline\n",
    "(Feature_1, Feature_2) = 12.62 \\newline\n",
    "(Feature_1, Feature_3) = -8.14 \\newline\n",
    "(Feature_2, Feature_3) = 37.20 \\newline\n",
    "(Feature_1, Feature_2, Feature_3) = 13.52\n",
    "$$\n",
    "\n",
    "Note that *a model with no features predicts E[y].*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking the big equation, I'll start solving it manually.\n",
    "$$\n",
    "\\phi_j(\\text{val}) = \\sum_{S \\subseteq \\{1,\\dots,p\\} \\setminus \\{j\\}} \\frac{|S|! (p - |S| - 1)!}{p!} \\left( \\text{val}(S \\cup \\{j\\}) - \\text{val}(S) \\right)\n",
    "$$\n",
    "\n",
    "For the intercept, we must exclude all coalisions that the intercept takes part and solve the summation. In this case we have 4 coalisions that intercept does not participate.\n",
    "$$\n",
    "\\phi_1(\\text{val}) = \\frac{1}{3!}( \\newline\n",
    "                                0! (3 - 0 - 1)! \\left[ \\text{val}(\\{Feature_1\\}) - \\text{val}(\\empty) \\right] + \\newline \n",
    "                                1! (3 - 1 - 1)! \\left[ \\text{val}(\\{Feature_1, Feature_2\\}) - \\text{val}(Feature_2) \\right] + \\newline \n",
    "                                1! (3 - 1 - 1)! \\left[ \\text{val}(\\{Feature_1, Feature_3\\}) - \\text{val}(Feature_3) \\right] + \\newline\n",
    "                                2! (3 - 2 - 1)! \\left[ \\text{val}(\\{Feature_1, Feature_2, Feature_3\\}) - \\text{val}(Feature_2, Feature_3) \\right])\n",
    "                                \n",
    "$$\n",
    "\n",
    "Using the values we previously calculated:\n",
    "\n",
    "$$\n",
    "\\phi_1(\\text{val}) = \\frac{1}{6}(0! (2)! [-8.26 - 4.96] + 1! (1)! [ 12.62 - 35.33] + 1! (1)! [ -8.14 - 5.37 ] + 2! (0)! [ 13.52 - 37.20 ])                    \n",
    "$$\n",
    "\n",
    "$$\n",
    "\\phi_1(\\text{val}) = \\frac{1}{6}(1 \\cdot 2 \\cdot -13.22 + 1 \\cdot 1 \\cdot -22.71 + 1 \\cdot 1 \\cdot -13.51 + 2 \\cdot 1 \\cdot -23.68) = -18.336 \n",
    "$$\n",
    "\n",
    "Doing the same for the others:\n",
    "$$\n",
    "\\phi_2(\\text{val}) = \\frac{1}{3!}( \\newline\n",
    "                                0! (3 - 0 - 1)! \\left[ \\text{val}(\\{Feature_2\\}) - \\text{val}(\\empty) \\right] + \\newline \n",
    "                                1! (3 - 1 - 1)! \\left[ \\text{val}(\\{Feature_1, Feature_2\\}) - \\text{val}(Feature_1) \\right] + \\newline \n",
    "                                1! (3 - 1 - 1)! \\left[ \\text{val}(\\{Feature_2, Feature_3\\}) - \\text{val}(Feature_3) \\right] + \\newline\n",
    "                                2! (3 - 2 - 1)! \\left[ \\text{val}(\\{Feature_1, Feature_2, Feature_3\\}) - \\text{val}(Feature_1, Feature_3) \\right])\n",
    "                                \n",
    "$$\n",
    "$$\n",
    "\\phi_2(\\text{val}) = \\frac{1}{6}(0! (2)! [35.33 - 4.96] + 1! (1)! [ 12.62 + 8.26] + 1! (1)! [ 37.20 - 5.37 ] + 2! (0)! [ 13.52 + 8.14 ])                    \n",
    "$$\n",
    "$$\n",
    "\\phi_2(\\text{val}) = \\frac{1}{6}(1 \\cdot 2 \\cdot 30.37 + 1 \\cdot 1 \\cdot 20.88 + 1 \\cdot 1 \\cdot 31.83 + 2 \\cdot 1 \\cdot 21.66) = 26.13\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\phi_3(\\text{val}) = \\frac{1}{3!}( \\newline\n",
    "                                0! (3 - 0 - 1)! \\left[ \\text{val}(\\{Feature_3\\}) - \\text{val}(\\empty) \\right] + \\newline \n",
    "                                1! (3 - 1 - 1)! \\left[ \\text{val}(\\{Feature_1, Feature_3\\}) - \\text{val}(Feature_1) \\right] + \\newline \n",
    "                                1! (3 - 1 - 1)! \\left[ \\text{val}(\\{Feature_2, Feature_3\\}) - \\text{val}(Feature_2) \\right] + \\newline\n",
    "                                2! (3 - 2 - 1)! \\left[ \\text{val}(\\{Feature_1, Feature_2, Feature_3\\}) - \\text{val}(Feature_1, Feature_2) \\right])\n",
    "                                \n",
    "$$\n",
    "$$\n",
    "\\phi_3(\\text{val}) = \\frac{1}{6}(0! (2)! [5.37 - 4.96] + 1! (1)! [ -8.14 + 8.26] + 1! (1)! [ 37.20 - 35.33 ] + 2! (0)! [ 13.52 - 12.62])                    \n",
    "$$\n",
    "$$\n",
    "\\phi_3(\\text{val}) = \\frac{1}{6}(1 \\cdot 2 \\cdot 0.41 + 1 \\cdot 1 \\cdot 0.12 + 1 \\cdot 1 \\cdot 1.87 + 2 \\cdot 1 \\cdot 0.90) = 0.76\n",
    "$$\n",
    "\n",
    "**Note that all of those calculations were done for a single instance of our original dataset. This is why computing shapvalues is quite an expensive feat!**\n",
    "\n",
    "$$\n",
    "(\\phi_1(\\text{val}), \\phi_2(\\text{val}), \\phi_3(\\text{val})) = (-18.336, 26.13, 0.76)\n",
    "$$\n",
    "\n",
    "Below, I'll create a simple function to generate shapvalues for every single instance of our 100 row dataset. The \"time complexity\" for a optimal solution of this problem would be something near O(2^p) with p as features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I'll base this implementation on the one here https://randomrealizations.com/posts/shap-from-scratch/#what-is-shap\n",
    "from math import factorial\n",
    "\n",
    "class ShapExplainerByMyself:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def explain(self, X, y, feature_of_interest = 1):\n",
    "        self.n_features = X.shape[1]\n",
    "        self.y_mean = y.mean()\n",
    "\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "        self.model_cache = {}\n",
    "        return self.compute_single_shap_value(feature_of_interest)\n",
    "        \n",
    "    def get_all_other_feature_subsets(self, feature_of_interest):\n",
    "        all_other_features = [j for j in range(self.n_features) if j != feature_of_interest]\n",
    "        return chain.from_iterable(combinations(all_other_features, r) for r in range(len(all_other_features)+1)) # THIS IS |S|\n",
    "    \n",
    "    def subset_model(self, feature_subset, instance):\n",
    "        # This is the same as calculating the VALUE of given subset fitting a specific model for the features of given subset\n",
    "        assert len(instance.shape) == 1, 'Instance must be a 1D array'\n",
    "        if len(feature_subset) == 0:\n",
    "            return self.y_mean # a model with no features predicts E[y]\n",
    "        \n",
    "        if tuple(feature_subset) in self.model_cache:\n",
    "            model = self.model_cache[tuple(feature_subset)]\n",
    "        else:\n",
    "            X_subset = self.X.take(feature_subset, axis=1)\n",
    "            model = LinearRegression()\n",
    "            model.fit(X_subset, self.y)\n",
    "            self.model_cache[tuple(feature_subset)] = model\n",
    "\n",
    "        return model.predict(instance.take(feature_subset).reshape(1, -1))[0]\n",
    "    \n",
    "    def permutation_factor(self, n_subset):\n",
    "        # This is |S!| * (j - |S| - 1)! / j!\n",
    "        return factorial(n_subset) * factorial(self.n_features - n_subset - 1) / factorial(self.n_features)\n",
    "    \n",
    "    def compute_single_shap_value(self, feature_of_interest, instance = X[0, :]):\n",
    "        shap_value = 0\n",
    "        for subset in self.get_all_other_feature_subsets(feature_of_interest):\n",
    "            n_subset = len(subset)\n",
    "            prediction_without_feature = self.subset_model(\n",
    "                subset,\n",
    "                instance\n",
    "            )\n",
    "            prediction_with_feature = self.subset_model(\n",
    "                subset + (feature_of_interest,),\n",
    "                instance\n",
    "            )\n",
    "            factor = self.permutation_factor(n_subset)\n",
    "            shap_value += factor * (prediction_with_feature - prediction_without_feature)\n",
    "        return shap_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-18.3393630786159 26.130472847745505 0.7683326528153469\n"
     ]
    }
   ],
   "source": [
    "# Let's check if results are consistent:\n",
    "explainer = ShapExplainerByMyself()\n",
    "print(explainer.explain(X, y, 0), explainer.explain(X, y, 1), explainer.explain(X, y, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "They are! Now I'll implement a logic to compute for every instance in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I'll change my class a little bit to look more like the shap explainer class\n",
    "class ShapExplainerByMyself:\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.n_features = X.shape[1]\n",
    "        self.y_mean = y.mean()\n",
    "        self.model_cache = {}\n",
    "\n",
    "    def explain(self):\n",
    "        output = pd.DataFrame().reindex_like(self.X) # I'll use pandas b/c of compatibility but numpy would be best here.\n",
    "        for row in output.index:\n",
    "            for feature in range(self.n_features):\n",
    "                output.iloc[row, feature] = self.compute_single_shap_value(feature_of_interest= feature, instance = X[row, :])\n",
    "        return output\n",
    "        \n",
    "    def get_all_other_feature_subsets(self, feature_of_interest):\n",
    "        all_other_features = [j for j in range(self.n_features) if j != feature_of_interest]\n",
    "        return chain.from_iterable(combinations(all_other_features, r) for r in range(len(all_other_features)+1)) # THIS IS |S|\n",
    "    \n",
    "    def subset_model(self, feature_subset, instance):\n",
    "        # This is the same as calculating the VALUE of given subset fitting a specific model for the features of given subset\n",
    "        assert len(instance.shape) == 1, 'Instance must be a 1D array'\n",
    "        if len(feature_subset) == 0:\n",
    "            return self.y_mean # a model with no features predicts E[y]\n",
    "        \n",
    "        if tuple(feature_subset) in self.model_cache:\n",
    "            model = self.model_cache[tuple(feature_subset)]\n",
    "        else:\n",
    "            X_subset = self.X.take(feature_subset, axis=1)\n",
    "            model = LinearRegression()\n",
    "            model.fit(X_subset, self.y)\n",
    "            self.model_cache[tuple(feature_subset)] = model\n",
    "\n",
    "        return model.predict(instance.take(feature_subset).reshape(1, -1))[0]\n",
    "    \n",
    "    def permutation_factor(self, n_subset):\n",
    "        # This is |S!| * (j - |S| - 1)! / j!\n",
    "        return factorial(n_subset) * factorial(self.n_features - n_subset - 1) / factorial(self.n_features)\n",
    "    \n",
    "    def compute_single_shap_value(self, feature_of_interest, instance):\n",
    "        shap_value = 0\n",
    "        for subset in self.get_all_other_feature_subsets(feature_of_interest):\n",
    "            n_subset = len(subset)\n",
    "            prediction_without_feature = self.subset_model(\n",
    "                subset,\n",
    "                instance\n",
    "            )\n",
    "            prediction_with_feature = self.subset_model(\n",
    "                subset + (feature_of_interest,),\n",
    "                instance\n",
    "            )\n",
    "            factor = self.permutation_factor(n_subset)\n",
    "            shap_value += factor * (prediction_with_feature - prediction_without_feature)\n",
    "        return shap_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SHAP values for Feature 1: -1.8474111129762605e-15\n",
      "SHAP values for Feature 2: -4.263256414560601e-16\n",
      "SHAP values for Feature 3: 4.1744385725905884e-16\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "explainer = ShapExplainerByMyself(df_X, y)\n",
    "shap_values = explainer.explain()\n",
    "\n",
    "# SHAP feature-wise values (averaged over all data points)\n",
    "shap_feature_importance = shap_values.values.mean(axis=0)\n",
    "\n",
    "# Print feature-wise SHAP values\n",
    "print(f\"SHAP values for Feature 1: {shap_feature_importance[0]}\")\n",
    "print(f\"SHAP values for Feature 2: {shap_feature_importance[1]}\")\n",
    "print(f\"SHAP values for Feature 3: {shap_feature_importance[2]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SHAP values for Feature 1: -3.552713678800501e-16\n",
      "SHAP values for Feature 2: -3.552713678800501e-15\n",
      "SHAP values for Feature 3: 4.796163466380677e-16\n"
     ]
    }
   ],
   "source": [
    "import shap\n",
    "\n",
    "# Create a SHAP explainer for the linear regression model\n",
    "model = LinearRegression()\n",
    "model.fit(df_X, df_y)\n",
    "explainer = shap.LinearExplainer(model, df_X)\n",
    "\n",
    "# Calculate SHAP values for the dataset\n",
    "shap_values = explainer(df_X)\n",
    "\n",
    "# SHAP feature-wise values (averaged over all data points)\n",
    "shap_feature_importance = shap_values.values.mean(axis=0)\n",
    "\n",
    "# Print feature-wise SHAP values\n",
    "print(f\"SHAP values for Feature 1: {shap_feature_importance[0]}\")\n",
    "print(f\"SHAP values for Feature 2: {shap_feature_importance[1]}\")\n",
    "print(f\"SHAP values for Feature 3: {shap_feature_importance[2]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My implementation calculated SHAP values without approximation, whereas the SHAP package uses an approximation to make the computation feasible for large datasets and complex models. The fact that the results are so close, despite the SHAP package using kernel-based approximations, suggests that the package is highly accurate.\n",
    "\n",
    "The small discrepancies between my SHAP values and those of the SHAP package are most likely due to:\n",
    "   - Kernel-based approximations used by the SHAP package.\n",
    "   - The inherent limitations of floating-point precision in computers.\n",
    "   - The fact that I calculated SHAP values without approximation, whereas the SHAP package balances accuracy and computational efficiency.\n",
    "\n",
    "   These differences are negligible and do not affect the overall interpretation of feature importance in the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "I saw [this](https://youtu.be/fbrVvMU8T6o?si=G52c-L4T2uWGaGS8) youtube video to grasp on how to make the calculation more clearly and read the articles below:\n",
    "\n",
    "https://christophm.github.io/interpretable-ml-book/shap.html\n",
    "\n",
    "https://randomrealizations.com/posts/shap-from-scratch/#what-is-shap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
